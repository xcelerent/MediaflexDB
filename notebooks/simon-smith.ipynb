{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simon Smith\n",
    "\n",
    "## Overview\n",
    "\n",
    "Simon Smith from curatorial team asked to to run a title comparison between NTLC title agains tiles in Mediaflex. \n",
    "\n",
    "### Objectives\n",
    "\n",
    "1. Find any match title for NFSA main repo in Mediaflex against each NTLC title and provide a matching score to indicate how close the title match is.\n",
    "\n",
    "2. Provide a Power BI report together with the analysis excel file for Simon to further study like which system holds the best quality of the video, whether the matched video are indeed the same.\n",
    "\n",
    "## Solution Design\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\.conda\\envs\\nfsa-env\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VERSION_ID  TITLE_ID_FK              MOVIETITLE VERSIONMEDIUM  VERSIONNO  \\\n",
      "0       46705        46671           THE LAST WAVE          Film     400323   \n",
      "1       46706        46671           THE LAST WAVE          Film     496831   \n",
      "2       47156        47155  PICNIC AT HANGING ROCK          Film          3   \n",
      "3       47235        47234               DILLINGER          Film       8254   \n",
      "4       47287        47155  PICNIC AT HANGING ROCK          Film     629872   \n",
      "\n",
      "             PROGRAMTITLE PROGRAMMEDIUM PROGRAMSUBMEDIUM  PROGRAMYEAR  \\\n",
      "0           THE LAST WAVE  Moving Image             Film            0   \n",
      "1           THE LAST WAVE  Moving Image             Film            0   \n",
      "2  PICNIC AT HANGING ROCK  Moving Image             Film            0   \n",
      "3               DILLINGER  Moving Image             Film            0   \n",
      "4  PICNIC AT HANGING ROCK  Moving Image             Film            0   \n",
      "\n",
      "  CONCATENATED_COUNTRIES CONCATENATED_LANGUAGES CONCATENATED_FORMS  \n",
      "0              Australia                English       Feature Film  \n",
      "1              Australia                English       Feature Film  \n",
      "2              Australia                English       Feature Film  \n",
      "3                  U.S.A                English       Feature Film  \n",
      "4              Australia                English       Feature Film  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the Excel files\n",
    "file_path_ntlc = '../data/NTLC/NTLC Collection Output April 2020.xlsx'\n",
    "file_path_mdd = '../data/Mediaflex/MDD-MoveList-Form-20240717.xlsx'\n",
    "# file_path_mdd = '../data/Mediaflex/MDD-MoveList-All-20240717.xlsx'\n",
    "\n",
    "\n",
    "# Read the Excel files\n",
    "df_ntlc = pd.read_excel(file_path_ntlc)\n",
    "df_mdd = pd.read_excel(file_path_mdd, sheet_name='Export Worksheet')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "# print(df_ntlc.head())\n",
    "# print(df_mdd.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../data/output/matching_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Load the Excel files\n",
    "file_path_ntlc = '../data/NTLC/NTLC Collection Output April 2020.xlsx'\n",
    "file_path_mdd = '../data/Mediaflex/MDD-MoveList-Form-20240717v1.xlsx'\n",
    "\n",
    "df_ntlc = pd.read_excel(file_path_ntlc)\n",
    "df_mdd = pd.read_excel(file_path_mdd, sheet_name='Export Worksheet')\n",
    "\n",
    "# Convert FTITLE and MOVIETITLE columns to strings\n",
    "df_ntlc['FTITLE'] = df_ntlc['FTITLE'].astype(str)\n",
    "df_mdd['MOVIETITLE'] = df_mdd['MOVIETITLE'].astype(str)\n",
    "\n",
    "# Function to get the best match title and score\n",
    "def get_best_match_title(row, choices):\n",
    "    title = row['FTITLE']\n",
    "    best_match, score = process.extractOne(title, choices)\n",
    "    return pd.Series([best_match, score])\n",
    "\n",
    "# Find the best match title and score for each record in df_ntlc\n",
    "choices = df_mdd['MOVIETITLE'].tolist()\n",
    "df_ntlc[['MOVIETITLE', 'FuzzyMatchingScore']] = df_ntlc.apply(get_best_match_title, choices=choices, axis=1)\n",
    "\n",
    "# Merge df_ntlc with the relevant columns from df_mdd\n",
    "df_mdd_subset = df_mdd[['MOVIETITLE', 'VERSION_ID', 'TITLE_ID_FK', 'VERSIONNO', 'PROGRAMTITLE', 'PROGRAMYEAR', 'CONCATENATED_COUNTRIES', 'CONCATENATED_LANGUAGES', 'CONCATENATED_FORMS']]\n",
    "result = pd.merge(df_ntlc, df_mdd_subset, on='MOVIETITLE', how='left')\n",
    "\n",
    "# Save the result to a new Excel file\n",
    "output_file_path = '../data/output/matching_results.xlsx'\n",
    "result.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def calculate_similarity_score(title1, title2):\n",
    "    return fuzz.ratio(title1, title2) / 100.0\n",
    "\n",
    "# Create a function to find the best match and score for each title\n",
    "def find_best_matches(system1_titles, system2_titles):\n",
    "    matches = []\n",
    "    for title1 in system1_titles:\n",
    "        best_match = None\n",
    "        highest_score = 0\n",
    "        for title2 in system2_titles:\n",
    "            score = calculate_similarity_score(title1, title2)\n",
    "            if score > highest_score:\n",
    "                highest_score = score\n",
    "                best_match = title2\n",
    "        matches.append((title1, best_match, highest_score))\n",
    "    return matches\n",
    "\n",
    "# Get the matches and scores\n",
    "matches = find_best_matches(system1_titles, system2_titles)\n",
    "\n",
    "# Print the results\n",
    "for title1, best_match, score in matches:\n",
    "    print(f\"'{title1}' best matches with '{best_match}' with a score of {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\.conda\\envs\\nfsa-env\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to ../data/output/matching_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Load the Excel files\n",
    "file_path_ntlc = '../data/NTLC/NTLC Collection Output April 2020v1.xlsx'\n",
    "file_path_mdd = '../data/Mediaflex/MDD-MoveList-Form-20240717.xlsx'\n",
    "\n",
    "df_ntlc = pd.read_excel(file_path_ntlc)\n",
    "df_mdd = pd.read_excel(file_path_mdd, sheet_name='Export Worksheet')\n",
    "\n",
    "# Convert FTITLE and MOVIETITLE columns to strings\n",
    "df_ntlc['FTITLE'] = df_ntlc['FTITLE'].astype(str)\n",
    "df_mdd['MOVIETITLE'] = df_mdd['MOVIETITLE'].astype(str)\n",
    "\n",
    "# Function to get the best match title and score using fuzz.ratio\n",
    "def get_best_match_title(row, choices):\n",
    "    title = row['FTITLE'].lower()\n",
    "    best_match, score = None, 0\n",
    "    for choice in choices:\n",
    "        current_score = fuzz.ratio(title, choice.lower())\n",
    "        #  current_score = fuzz.token_set_ratio(title, choice.lower())\n",
    "        #  current_score = fuzz.token_set_ratio(title, choice.lower())\n",
    "        if current_score > score:\n",
    "            best_match, score = choice, current_score\n",
    "    return pd.Series([best_match, score])\n",
    "\n",
    "# Find the best match title and score for each record in df_ntlc\n",
    "choices = df_mdd['MOVIETITLE'].tolist()\n",
    "df_ntlc[['MOVIETITLE', 'FuzzyMatchingScore']] = df_ntlc.apply(get_best_match_title, choices=choices, axis=1)\n",
    "\n",
    "# Merge df_ntlc with the relevant columns from df_mdd\n",
    "df_mdd_subset = df_mdd[['MOVIETITLE', 'VERSION_ID', 'TITLE_ID_FK', 'VERSIONNO', 'PROGRAMTITLE', 'PROGRAMYEAR', 'CONCATENATED_COUNTRIES', 'CONCATENATED_LANGUAGES', 'CONCATENATED_FORMS']]\n",
    "result = pd.merge(df_ntlc, df_mdd_subset, on='MOVIETITLE', how='left')\n",
    "\n",
    "# Save the result to a new Excel file\n",
    "output_file_path = '../data/output/matching_results.xlsx'\n",
    "result.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\.conda\\envs\\nfsa-env\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m choices \u001b[38;5;241m=\u001b[39m df_mdd[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMOVIETITLE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Apply get_best_match_title in parallel\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmultiprocessing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_best_match_title\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchoices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf_ntlc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFTITLE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Convert results to DataFrame\u001b[39;00m\n\u001b[0;32m     31\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMOVIETITLE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFuzzyMatchingScore\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\nfsa-env\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\nfsa-env\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\nfsa-env\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Load the Excel files\n",
    "file_path_ntlc = '../data/NTLC/NTLC Collection Output April 2020v1.xlsx'\n",
    "file_path_mdd = '../data/Mediaflex/MDD-MoveList-Form-20240717.xlsx'\n",
    "\n",
    "df_ntlc = pd.read_excel(file_path_ntlc)\n",
    "df_mdd = pd.read_excel(file_path_mdd, sheet_name='Export Worksheet')\n",
    "\n",
    "# Convert FTITLE and MOVIETITLE columns to strings\n",
    "df_ntlc['FTITLE'] = df_ntlc['FTITLE'].astype(str)\n",
    "df_mdd['MOVIETITLE'] = df_mdd['MOVIETITLE'].astype(str)\n",
    "\n",
    "# Function to get the best match title and score using fuzz.ratio\n",
    "def get_best_match_title(row_title, choices):\n",
    "    title = row_title.lower()\n",
    "    scores = np.array([fuzz.ratio(title, choice.lower()) for choice in choices])\n",
    "    best_match_index = scores.argmax()\n",
    "    return choices[best_match_index], scores[best_match_index]\n",
    "\n",
    "# Convert choices to a list\n",
    "choices = df_mdd['MOVIETITLE'].tolist()\n",
    "\n",
    "# Apply get_best_match_title in parallel\n",
    "results = Parallel(n_jobs=-1, backend=\"multiprocessing\")(delayed(get_best_match_title)(title, choices) for title in df_ntlc['FTITLE'])\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['MOVIETITLE', 'FuzzyMatchingScore'])\n",
    "\n",
    "# Add results to df_ntlc\n",
    "df_ntlc[['MOVIETITLE', 'FuzzyMatchingScore']] = results_df\n",
    "\n",
    "# Merge df_ntlc with the relevant columns from df_mdd\n",
    "df_mdd_subset = df_mdd[['MOVIETITLE', 'VERSION_ID', 'TITLE_ID_FK', 'VERSIONNO', 'PROGRAMTITLE', 'PROGRAMYEAR', 'CONCATENATED_COUNTRIES', 'CONCATENATED_LANGUAGES', 'CONCATENATED_FORMS']]\n",
    "result = pd.merge(df_ntlc, df_mdd_subset, on='MOVIETITLE', how='left')\n",
    "\n",
    "# Save the result to a new Excel file\n",
    "output_file_path = '../data/output/matching_results.xlsx'\n",
    "result.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\.conda\\envs\\nfsa-env\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Apply get_best_match_title in parallel with progress bar\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmultiprocessing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_best_match_title\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchoices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_ntlc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFTITLE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProcessing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecord\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Convert results to DataFrame\u001b[39;00m\n\u001b[0;32m     38\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMOVIETITLE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFuzzyMatchingScore\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\nfsa-env\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\nfsa-env\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\nfsa-env\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Load the Excel files\n",
    "file_path_ntlc = '../data/NTLC/NTLC Collection Output April 2020.xlsx'\n",
    "file_path_mdd = '../data/Mediaflex/MDD-MoveList-Form-20240717.xlsx'\n",
    "\n",
    "df_ntlc = pd.read_excel(file_path_ntlc)\n",
    "df_mdd = pd.read_excel(file_path_mdd, sheet_name='Export Worksheet')\n",
    "\n",
    "# Convert FTITLE and MOVIETITLE columns to strings\n",
    "df_ntlc['FTITLE'] = df_ntlc['FTITLE'].astype(str)\n",
    "df_mdd['MOVIETITLE'] = df_mdd['MOVIETITLE'].astype(str)\n",
    "\n",
    "# Function to get the best match title and score using fuzz.ratio\n",
    "def get_best_match_title(row_title, choices):\n",
    "    title = row_title.lower()\n",
    "    scores = np.array([fuzz.ratio(title, choice.lower()) for choice in choices])\n",
    "    best_match_index = scores.argmax()\n",
    "    return choices[best_match_index], scores[best_match_index]\n",
    "\n",
    "# Convert choices to a list\n",
    "choices = df_mdd['MOVIETITLE'].tolist()\n",
    "\n",
    "# Measure start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Apply get_best_match_title in parallel with progress bar\n",
    "results = Parallel(n_jobs=12, backend=\"multiprocessing\")(\n",
    "    delayed(get_best_match_title)(title, choices) for title in tqdm(df_ntlc['FTITLE'], desc=\"Processing\", unit=\"record\")\n",
    ")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['MOVIETITLE', 'FuzzyMatchingScore'])\n",
    "\n",
    "# Add results to df_ntlc\n",
    "df_ntlc[['MOVIETITLE', 'FuzzyMatchingScore']] = results_df\n",
    "\n",
    "# Merge df_ntlc with the relevant columns from df_mdd\n",
    "df_mdd_subset = df_mdd[['MOVIETITLE', 'VERSION_ID', 'TITLE_ID_FK', 'VERSIONNO', 'PROGRAMTITLE', 'PROGRAMYEAR', 'CONCATENATED_COUNTRIES', 'CONCATENATED_LANGUAGES', 'CONCATENATED_FORMS']]\n",
    "result = pd.merge(df_ntlc, df_mdd_subset, on='MOVIETITLE', how='left')\n",
    "\n",
    "# Save the result to a new Excel file\n",
    "output_file_path = '../data/output/matching_results.xlsx'\n",
    "result.to_excel(output_file_path, index=False)\n",
    "\n",
    "# Measure end time\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Results saved to {output_file_path}\")\n",
    "print(f\"Processing time: {end_time - start_time} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfsa-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
